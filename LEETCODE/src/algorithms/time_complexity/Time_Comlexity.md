```c
    for (int i = 0; i < n; i++) {   // O(n)
    }
```

```c
    for (int i = n; i > 0 ; i--) {   // O(n)
    }
```

```c
    for (int i = 0; i < n ; i+2) {   // O(n/2)    => O(n)
    }
```

- If you touch each element once or loop linearly with a fixed step, it‚Äôs O(n).
- It doesn‚Äôt matter if you skip every 2nd, 5th, or 100th element ‚Üí constants vanish in Big-O.
- Constants don‚Äôt matter in Big-O (O(n/2), O(2n), O(5n) ‚Üí all O(n)).
- If you increase or decrease the loop variable linearly (i += k, i--, i += c), the loop will usually be O(n).

---

```c
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {     //  // O(n^2)
        }
    }
```
```c
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < i; j++) {     //  O(n^2)
        }
    }
```


```c
p = 0;
for (i = 1; p <= n; i++) {
    p = p + i;
}
```

---

## üîé Step-by-step Execution

At each iteration:

* When `i = 1` ‚Üí `p = 0 + 1 = 1`
* When `i = 2` ‚Üí `p = 1 + 2 = 3`
* When `i = 3` ‚Üí `p = 1 + 2 + 3`
* When `i = 4` ‚Üí `p = 1 + 2 + 3 + 4`
* ‚Ä¶
* When `i = k` ‚Üí `p = 1 + 2 + 3 + ‚Ä¶ + k`

So after `k` iterations:

$$
p = \frac{k(k+1)}{2}
$$

---

## üìê Loop Condition

The loop continues **while `p <= n`**.
So we stop when:

$$
\frac{k(k+1)}{2} > n
$$

Ignoring constants:

$$
k^2 > n
$$

$$
k > \sqrt{n}
$$

---

## ‚è±Ô∏è Time Complexity

Therefore, the loop runs about **‚àön times**.

$$
\boxed{O(\sqrt{n})}
$$

---

# ‚è≥ Time Complexity Analysis

```c
for (i = 1; i < n; i = i * 2) {
    stmt;
}
```

---

## üîé Step-by-step Execution

At each iteration:

* When `i = 1`
* Next: `i = 1 * 2 = 2 = 2¬π`
* Next: `i = 2 * 2 = 4 = 2¬≤`
* Next: `i = 4 * 2 = 8 = 2¬≥`
* ‚Ä¶
* After `k` iterations: `i = 2^k`

---

## üìê Loop Condition

The loop runs while `i < n`.
So the stopping point is when:

$$
2^k \geq n
$$

Taking log base 2:

$$
k \geq \log_2(n)
$$

---

## ‚è±Ô∏è Time Complexity

Thus, the loop runs about **log‚ÇÇ(n) times**.

$$
\boxed{O(\log n)}
$$

---

‚úÖ Key Insight:
Whenever the loop variable **grows or shrinks multiplicatively** (e.g., `i = i*2`, `i = i/2`), the complexity is **O(log n)** instead of **O(n)**.



